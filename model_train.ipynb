{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RVl4o55Tck8l"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the datasets\n",
        "true_news = pd.read_csv('True.csv')\n",
        "fake_news = pd.read_csv('Fake.csv')\n",
        "\n",
        "# Combine the datasets and add a label\n",
        "true_news['label'] = 1  # Label for true news\n",
        "fake_news['label'] = 0  # Label for fake news\n",
        "\n",
        "# Combine into a single dataframe\n",
        "news_data = pd.concat([true_news, fake_news], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "urkYUGzkc830"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# List of basic stopwords (you can use a larger list if needed)\n",
        "stopwords = set([\"the\", \"and\", \"a\", \"is\", \"in\", \"it\", \"for\", \"to\", \"of\", \"that\", \"on\", \"this\", \"with\", \"as\", \"by\", \"at\", \"from\", \"an\", \"be\"])\n",
        "\n",
        "# Data Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove all non-word characters (punctuation, etc.)\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "dBltpDHadBIh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply preprocessing\n",
        "news_data['text'] = news_data['title'] + ' ' + news_data['text']\n",
        "news_data['text'] = news_data['text'].apply(preprocess_text)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X = news_data['text']\n",
        "y = news_data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the pipeline with TF-IDF Vectorizer and Logistic Regression\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000)),  # Limit max features to prevent overfitting\n",
        "    ('model', LogisticRegression())\n",
        "])\n"
      ],
      "metadata": {
        "id": "qxIsM8APc7ee"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Save the trained model\n",
        "with open('news_classifier.pkl', 'wb') as model_file:\n",
        "    pickle.dump(pipeline, model_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q93mEMTdKMv",
        "outputId": "5625905b-22e8-4455-d9ed-be64847bf530"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 98.88%\n"
          ]
        }
      ]
    }
  ]
}